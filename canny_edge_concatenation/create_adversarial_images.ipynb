{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "def make_ppm(source_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            with Image.open(file_path) as img:    \n",
    "                output_filename = os.path.splitext(filename)[0] + '.ppm'\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "                img.save(output_path, 'PPM')\n",
    "    print(\"Conversion complete.\")\n",
    "    \n",
    "input = \"../gtsrb-german-traffic-sign/Test\"\n",
    "output = \"./input/GTSRB_Final_Test_Images/GTSRB/Final_Test/baseline_pgd_attack/all_ppm\"\n",
    "make_ppm(input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Not loading pre-trained weights\n",
      "[INFO]: Freezing hidden layers...\n",
      "06578.ppm not in CSV\n",
      "11004.ppm not in CSV\n",
      "01217.ppm not in CSV\n",
      "00109.ppm not in CSV\n",
      "09893.ppm not in CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artijain/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/artijain/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08555.ppm not in CSV\n",
      "03400.ppm not in CSV\n",
      "02078.ppm not in CSV\n",
      "04409.ppm not in CSV\n",
      "08233.ppm not in CSV\n",
      "11762.ppm not in CSV\n",
      "10468.ppm not in CSV\n",
      "08227.ppm not in CSV\n",
      "09139.ppm not in CSV\n",
      "05703.ppm not in CSV\n",
      "03372.ppm not in CSV\n",
      "03414.ppm not in CSV\n",
      "12519.ppm not in CSV\n",
      "05065.ppm not in CSV\n",
      "11010.ppm not in CSV\n",
      "01203.ppm not in CSV\n",
      "09887.ppm not in CSV\n",
      "07672.ppm not in CSV\n",
      "08541.ppm not in CSV\n",
      "04353.ppm not in CSV\n",
      "12531.ppm not in CSV\n",
      "11038.ppm not in CSV\n",
      "06544.ppm not in CSV\n",
      "07882.ppm not in CSV\n",
      "00135.ppm not in CSV\n",
      "08569.ppm not in CSV\n",
      "10326.ppm not in CSV\n",
      "11986.ppm not in CSV\n",
      "00653.ppm not in CSV\n",
      "06222.ppm not in CSV\n",
      "12257.ppm not in CSV\n",
      "02044.ppm not in CSV\n",
      "04435.ppm not in CSV\n",
      "12243.ppm not in CSV\n",
      "04421.ppm not in CSV\n",
      "10454.ppm not in CSV\n",
      "00647.ppm not in CSV\n",
      "11992.ppm not in CSV\n",
      "01559.ppm not in CSV\n",
      "09105.ppm not in CSV\n",
      "06236.ppm not in CSV\n",
      "06550.ppm not in CSV\n",
      "07896.ppm not in CSV\n",
      "00121.ppm not in CSV\n",
      "10332.ppm not in CSV\n",
      "03428.ppm not in CSV\n",
      "05059.ppm not in CSV\n",
      "12525.ppm not in CSV\n",
      "02905.ppm not in CSV\n",
      "09850.ppm not in CSV\n",
      "08596.ppm not in CSV\n",
      "09688.ppm not in CSV\n",
      "00874.ppm not in CSV\n",
      "11979.ppm not in CSV\n",
      "05918.ppm not in CSV\n",
      "00860.ppm not in CSV\n",
      "09844.ppm not in CSV\n",
      "08582.ppm not in CSV\n",
      "07699.ppm not in CSV\n",
      "07841.ppm not in CSV\n",
      "04390.ppm not in CSV\n",
      "03399.ppm not in CSV\n",
      "12294.ppm not in CSV\n",
      "02087.ppm not in CSV\n",
      "10483.ppm not in CSV\n",
      "00690.ppm not in CSV\n",
      "10497.ppm not in CSV\n",
      "11951.ppm not in CSV\n",
      "05924.ppm not in CSV\n",
      "12280.ppm not in CSV\n",
      "09878.ppm not in CSV\n",
      "06593.ppm not in CSV\n",
      "11560.ppm not in CSV\n",
      "01773.ppm not in CSV\n",
      "08031.ppm not in CSV\n",
      "05515.ppm not in CSV\n",
      "12069.ppm not in CSV\n",
      "05273.ppm not in CSV\n",
      "10118.ppm not in CSV\n",
      "08757.ppm not in CSV\n",
      "07464.ppm not in CSV\n",
      "11206.ppm not in CSV\n",
      "08743.ppm not in CSV\n",
      "07470.ppm not in CSV\n",
      "11212.ppm not in CSV\n",
      "05267.ppm not in CSV\n",
      "02508.ppm not in CSV\n",
      "03616.ppm not in CSV\n",
      "04179.ppm not in CSV\n",
      "03170.ppm not in CSV\n",
      "05501.ppm not in CSV\n",
      "11574.ppm not in CSV\n",
      "06008.ppm not in CSV\n",
      "00479.ppm not in CSV\n",
      "08025.ppm not in CSV\n",
      "07316.ppm not in CSV\n",
      "03158.ppm not in CSV\n",
      "02246.ppm not in CSV\n",
      "00451.ppm not in CSV\n",
      "09475.ppm not in CSV\n",
      "02520.ppm not in CSV\n",
      "02534.ppm not in CSV\n",
      "00323.ppm not in CSV\n",
      "06752.ppm not in CSV\n",
      "09461.ppm not in CSV\n",
      "06034.ppm not in CSV\n",
      "11548.ppm not in CSV\n",
      "09307.ppm not in CSV\n",
      "08019.ppm not in CSV\n",
      "01983.ppm not in CSV\n",
      "02252.ppm not in CSV\n",
      "12041.ppm not in CSV\n",
      "04810.ppm not in CSV\n",
      "08794.ppm not in CSV\n",
      "03819.ppm not in CSV\n",
      "08958.ppm not in CSV\n",
      "04804.ppm not in CSV\n",
      "00492.ppm not in CSV\n",
      "01954.ppm not in CSV\n",
      "10859.ppm not in CSV\n",
      "02285.ppm not in CSV\n",
      "12096.ppm not in CSV\n",
      "08964.ppm not in CSV\n",
      "06791.ppm not in CSV\n",
      "04186.ppm not in CSV\n",
      "05298.ppm not in CSV\n",
      "04838.ppm not in CSV\n",
      "12082.ppm not in CSV\n",
      "10695.ppm not in CSV\n",
      "01940.ppm not in CSV\n",
      "01798.ppm not in CSV\n",
      "08145.ppm not in CSV\n",
      "07276.ppm not in CSV\n",
      "00519.ppm not in CSV\n",
      "01607.ppm not in CSV\n",
      "11414.ppm not in CSV\n",
      "06168.ppm not in CSV\n",
      "05461.ppm not in CSV\n",
      "03010.ppm not in CSV\n",
      "02468.ppm not in CSV\n",
      "11372.ppm not in CSV\n",
      "01161.ppm not in CSV\n",
      "07510.ppm not in CSV\n",
      "09529.ppm not in CSV\n",
      "11366.ppm not in CSV\n",
      "10078.ppm not in CSV\n",
      "07504.ppm not in CSV\n",
      "05313.ppm not in CSV\n",
      "05475.ppm not in CSV\n",
      "08151.ppm not in CSV\n",
      "07262.ppm not in CSV\n",
      "12121.ppm not in CSV\n",
      "02332.ppm not in CSV\n",
      "04743.ppm not in CSV\n",
      "08179.ppm not in CSV\n",
      "10736.ppm not in CSV\n",
      "00525.ppm not in CSV\n",
      "06154.ppm not in CSV\n",
      "09267.ppm not in CSV\n",
      "06632.ppm not in CSV\n",
      "09501.ppm not in CSV\n",
      "10050.ppm not in CSV\n",
      "04025.ppm not in CSV\n",
      "03992.ppm not in CSV\n",
      "03986.ppm not in CSV\n",
      "06626.ppm not in CSV\n",
      "09515.ppm not in CSV\n",
      "01149.ppm not in CSV\n",
      "00257.ppm not in CSV\n",
      "07538.ppm not in CSV\n",
      "10044.ppm not in CSV\n",
      "10722.ppm not in CSV\n",
      "00531.ppm not in CSV\n",
      "06140.ppm not in CSV\n",
      "12135.ppm not in CSV\n",
      "05449.ppm not in CSV\n",
      "02326.ppm not in CSV\n",
      "09298.ppm not in CSV\n",
      "08186.ppm not in CSV\n",
      "08838.ppm not in CSV\n",
      "06801.ppm not in CSV\n",
      "10905.ppm not in CSV\n",
      "08192.ppm not in CSV\n",
      "01808.ppm not in CSV\n",
      "04970.ppm not in CSV\n",
      "06197.ppm not in CSV\n",
      "01820.ppm not in CSV\n",
      "04780.ppm not in CSV\n",
      "04958.ppm not in CSV\n",
      "02497.ppm not in CSV\n",
      "03951.ppm not in CSV\n",
      "03789.ppm not in CSV\n",
      "06829.ppm not in CSV\n",
      "00280.ppm not in CSV\n",
      "10093.ppm not in CSV\n",
      "00294.ppm not in CSV\n",
      "10087.ppm not in CSV\n",
      "11399.ppm not in CSV\n",
      "02483.ppm not in CSV\n",
      "04794.ppm not in CSV\n",
      "06183.ppm not in CSV\n",
      "01834.ppm not in CSV\n",
      "08421.ppm not in CSV\n",
      "11170.ppm not in CSV\n",
      "12479.ppm not in CSV\n",
      "05105.ppm not in CSV\n",
      "05663.ppm not in CSV\n",
      "09059.ppm not in CSV\n",
      "11616.ppm not in CSV\n",
      "01405.ppm not in CSV\n",
      "07074.ppm not in CSV\n",
      "10508.ppm not in CSV\n",
      "11602.ppm not in CSV\n",
      "01411.ppm not in CSV\n",
      "08353.ppm not in CSV\n",
      "04569.ppm not in CSV\n",
      "03206.ppm not in CSV\n",
      "02118.ppm not in CSV\n",
      "05677.ppm not in CSV\n",
      "03560.ppm not in CSV\n",
      "08435.ppm not in CSV\n",
      "01377.ppm not in CSV\n",
      "06418.ppm not in CSV\n",
      "12445.ppm not in CSV\n",
      "02656.ppm not in CSV\n",
      "03548.ppm not in CSV\n",
      "10252.ppm not in CSV\n",
      "00041.ppm not in CSV\n",
      "09703.ppm not in CSV\n",
      "06356.ppm not in CSV\n",
      "01439.ppm not in CSV\n",
      "10534.ppm not in CSV\n",
      "07048.ppm not in CSV\n",
      "05887.ppm not in CSV\n",
      "12323.ppm not in CSV\n",
      "04555.ppm not in CSV\n",
      "05893.ppm not in CSV\n",
      "09071.ppm not in CSV\n",
      "00733.ppm not in CSV\n",
      "10520.ppm not in CSV\n",
      "08409.ppm not in CSV\n",
      "10246.ppm not in CSV\n",
      "11158.ppm not in CSV\n",
      "09717.ppm not in CSV\n",
      "06424.ppm not in CSV\n",
      "12451.ppm not in CSV\n",
      "02642.ppm not in CSV\n",
      "02871.ppm not in CSV\n",
      "09924.ppm not in CSV\n",
      "08384.ppm not in CSV\n",
      "05878.ppm not in CSV\n",
      "11819.ppm not in CSV\n",
      "08390.ppm not in CSV\n",
      "00914.ppm not in CSV\n",
      "02865.ppm not in CSV\n",
      "07935.ppm not in CSV\n",
      "00082.ppm not in CSV\n",
      "09918.ppm not in CSV\n",
      "12486.ppm not in CSV\n",
      "02695.ppm not in CSV\n",
      "05844.ppm not in CSV\n",
      "06395.ppm not in CSV\n",
      "11825.ppm not in CSV\n",
      "00928.ppm not in CSV\n",
      "06381.ppm not in CSV\n",
      "04596.ppm not in CSV\n",
      "05850.ppm not in CSV\n",
      "12492.ppm not in CSV\n",
      "10285.ppm not in CSV\n",
      "00096.ppm not in CSV\n",
      "05851.ppm not in CSV\n",
      "04597.ppm not in CSV\n",
      "06380.ppm not in CSV\n",
      "00929.ppm not in CSV\n",
      "11824.ppm not in CSV\n",
      "00097.ppm not in CSV\n",
      "10284.ppm not in CSV\n",
      "01389.ppm not in CSV\n",
      "02858.ppm not in CSV\n",
      "12487.ppm not in CSV\n",
      "00083.ppm not in CSV\n",
      "09919.ppm not in CSV\n",
      "07934.ppm not in CSV\n",
      "06394.ppm not in CSV\n",
      "11830.ppm not in CSV\n",
      "05845.ppm not in CSV\n",
      "04583.ppm not in CSV\n",
      "00915.ppm not in CSV\n",
      "08391.ppm not in CSV\n",
      "11818.ppm not in CSV\n",
      "02864.ppm not in CSV\n",
      "09931.ppm not in CSV\n",
      "05879.ppm not in CSV\n",
      "00901.ppm not in CSV\n",
      "08385.ppm not in CSV\n",
      "06343.ppm not in CSV\n",
      "02125.ppm not in CSV\n",
      "05892.ppm not in CSV\n",
      "04554.ppm not in CSV\n",
      "04232.ppm not in CSV\n",
      "12450.ppm not in CSV\n",
      "11159.ppm not in CSV\n",
      "09716.ppm not in CSV\n",
      "00054.ppm not in CSV\n",
      "08408.ppm not in CSV\n",
      "10247.ppm not in CSV\n",
      "09702.ppm not in CSV\n",
      "00040.ppm not in CSV\n",
      "10253.ppm not in CSV\n",
      "04226.ppm not in CSV\n",
      "03549.ppm not in CSV\n",
      "02657.ppm not in CSV\n",
      "05138.ppm not in CSV\n",
      "12322.ppm not in CSV\n",
      "02131.ppm not in CSV\n",
      "07049.ppm not in CSV\n",
      "10535.ppm not in CSV\n",
      "01438.ppm not in CSV\n",
      "05676.ppm not in CSV\n",
      "02119.ppm not in CSV\n",
      "03207.ppm not in CSV\n",
      "04568.ppm not in CSV\n",
      "08352.ppm not in CSV\n",
      "07061.ppm not in CSV\n",
      "01410.ppm not in CSV\n",
      "01376.ppm not in CSV\n",
      "00068.ppm not in CSV\n",
      "07707.ppm not in CSV\n",
      "03561.ppm not in CSV\n",
      "05110.ppm not in CSV\n",
      "03575.ppm not in CSV\n",
      "12478.ppm not in CSV\n",
      "11171.ppm not in CSV\n",
      "01362.ppm not in CSV\n",
      "08420.ppm not in CSV\n",
      "07713.ppm not in CSV\n",
      "10509.ppm not in CSV\n",
      "08346.ppm not in CSV\n",
      "07075.ppm not in CSV\n",
      "01404.ppm not in CSV\n",
      "09058.ppm not in CSV\n",
      "11617.ppm not in CSV\n",
      "05662.ppm not in CSV\n",
      "03944.ppm not in CSV\n",
      "02482.ppm not in CSV\n",
      "08811.ppm not in CSV\n",
      "10086.ppm not in CSV\n",
      "06182.ppm not in CSV\n",
      "04781.ppm not in CSV\n",
      "07288.ppm not in CSV\n",
      "08805.ppm not in CSV\n",
      "10092.ppm not in CSV\n",
      "06828.ppm not in CSV\n",
      "03788.ppm not in CSV\n",
      "03950.ppm not in CSV\n",
      "02496.ppm not in CSV\n",
      "06800.ppm not in CSV\n",
      "03978.ppm not in CSV\n",
      "04971.ppm not in CSV\n",
      "10904.ppm not in CSV\n",
      "08187.ppm not in CSV\n",
      "09299.ppm not in CSV\n",
      "10910.ppm not in CSV\n",
      "08839.ppm not in CSV\n",
      "06814.ppm not in CSV\n",
      "10045.ppm not in CSV\n",
      "01148.ppm not in CSV\n",
      "09514.ppm not in CSV\n",
      "03987.ppm not in CSV\n",
      "04030.ppm not in CSV\n",
      "04756.ppm not in CSV\n",
      "03039.ppm not in CSV\n",
      "05448.ppm not in CSV\n",
      "12134.ppm not in CSV\n",
      "06141.ppm not in CSV\n",
      "00530.ppm not in CSV\n",
      "10723.ppm not in CSV\n",
      "11429.ppm not in CSV\n",
      "06155.ppm not in CSV\n",
      "04742.ppm not in CSV\n",
      "02333.ppm not in CSV\n",
      "12120.ppm not in CSV\n",
      "02455.ppm not in CSV\n",
      "04024.ppm not in CSV\n",
      "10051.ppm not in CSV\n",
      "00242.ppm not in CSV\n",
      "09500.ppm not in CSV\n",
      "06633.ppm not in CSV\n",
      "03763.ppm not in CSV\n",
      "07505.ppm not in CSV\n",
      "08636.ppm not in CSV\n",
      "01174.ppm not in CSV\n",
      "09528.ppm not in CSV\n",
      "11367.ppm not in CSV\n",
      "11401.ppm not in CSV\n",
      "01612.ppm not in CSV\n",
      "07263.ppm not in CSV\n",
      "05474.ppm not in CSV\n",
      "03011.ppm not in CSV\n",
      "05460.ppm not in CSV\n",
      "06169.ppm not in CSV\n",
      "11415.ppm not in CSV\n",
      "01606.ppm not in CSV\n",
      "00518.ppm not in CSV\n",
      "07277.ppm not in CSV\n",
      "07511.ppm not in CSV\n",
      "01160.ppm not in CSV\n",
      "11373.ppm not in CSV\n",
      "05306.ppm not in CSV\n",
      "05299.ppm not in CSV\n",
      "04187.ppm not in CSV\n",
      "06948.ppm not in CSV\n",
      "06790.ppm not in CSV\n",
      "01799.ppm not in CSV\n",
      "01941.ppm not in CSV\n",
      "00487.ppm not in CSV\n",
      "04839.ppm not in CSV\n",
      "02284.ppm not in CSV\n",
      "10680.ppm not in CSV\n",
      "00493.ppm not in CSV\n",
      "08971.ppm not in CSV\n",
      "03824.ppm not in CSV\n",
      "04193.ppm not in CSV\n",
      "08959.ppm not in CSV\n",
      "04805.ppm not in CSV\n",
      "10864.ppm not in CSV\n",
      "01969.ppm not in CSV\n",
      "04811.ppm not in CSV\n",
      "03818.ppm not in CSV\n",
      "06960.ppm not in CSV\n",
      "08795.ppm not in CSV\n",
      "09460.ppm not in CSV\n",
      "00322.ppm not in CSV\n",
      "10131.ppm not in CSV\n",
      "02535.ppm not in CSV\n",
      "12040.ppm not in CSV\n",
      "04622.ppm not in CSV\n",
      "01982.ppm not in CSV\n",
      "00444.ppm not in CSV\n",
      "09306.ppm not in CSV\n",
      "06035.ppm not in CSV\n",
      "10643.ppm not in CSV\n",
      "00450.ppm not in CSV\n",
      "09312.ppm not in CSV\n",
      "06021.ppm not in CSV\n",
      "05528.ppm not in CSV\n",
      "02247.ppm not in CSV\n",
      "03159.ppm not in CSV\n",
      "04636.ppm not in CSV\n",
      "02521.ppm not in CSV\n",
      "09474.ppm not in CSV\n",
      "00336.ppm not in CSV\n",
      "10125.ppm not in CSV\n",
      "07459.ppm not in CSV\n",
      "04178.ppm not in CSV\n",
      "03617.ppm not in CSV\n",
      "02509.ppm not in CSV\n",
      "05266.ppm not in CSV\n",
      "11213.ppm not in CSV\n",
      "01000.ppm not in CSV\n",
      "07471.ppm not in CSV\n",
      "07317.ppm not in CSV\n",
      "08024.ppm not in CSV\n",
      "00478.ppm not in CSV\n",
      "06009.ppm not in CSV\n",
      "11575.ppm not in CSV\n",
      "05500.ppm not in CSV\n",
      "03171.ppm not in CSV\n",
      "12068.ppm not in CSV\n",
      "05514.ppm not in CSV\n",
      "03165.ppm not in CSV\n",
      "11207.ppm not in CSV\n",
      "10119.ppm not in CSV\n",
      "03603.ppm not in CSV\n",
      "02092.ppm not in CSV\n",
      "12281.ppm not in CSV\n",
      "11950.ppm not in CSV\n",
      "10496.ppm not in CSV\n",
      "11788.ppm not in CSV\n",
      "07854.ppm not in CSV\n",
      "06592.ppm not in CSV\n",
      "09879.ppm not in CSV\n",
      "04385.ppm not in CSV\n",
      "02938.ppm not in CSV\n",
      "04391.ppm not in CSV\n",
      "07840.ppm not in CSV\n",
      "07698.ppm not in CSV\n",
      "00691.ppm not in CSV\n",
      "11944.ppm not in CSV\n",
      "10482.ppm not in CSV\n",
      "00849.ppm not in CSV\n",
      "12295.ppm not in CSV\n",
      "03398.ppm not in CSV\n",
      "05931.ppm not in CSV\n",
      "00861.ppm not in CSV\n",
      "05919.ppm not in CSV\n",
      "02910.ppm not in CSV\n",
      "08583.ppm not in CSV\n",
      "09845.ppm not in CSV\n",
      "09689.ppm not in CSV\n",
      "08597.ppm not in CSV\n",
      "09851.ppm not in CSV\n",
      "02904.ppm not in CSV\n",
      "11978.ppm not in CSV\n",
      "06237.ppm not in CSV\n",
      "09104.ppm not in CSV\n",
      "07129.ppm not in CSV\n",
      "04420.ppm not in CSV\n",
      "12524.ppm not in CSV\n",
      "05058.ppm not in CSV\n",
      "02737.ppm not in CSV\n",
      "04346.ppm not in CSV\n",
      "10333.ppm not in CSV\n",
      "00120.ppm not in CSV\n",
      "07897.ppm not in CSV\n",
      "09662.ppm not in CSV\n",
      "10327.ppm not in CSV\n",
      "07883.ppm not in CSV\n",
      "06545.ppm not in CSV\n",
      "09676.ppm not in CSV\n",
      "02723.ppm not in CSV\n",
      "06223.ppm not in CSV\n",
      "09110.ppm not in CSV\n",
      "00652.ppm not in CSV\n",
      "11987.ppm not in CSV\n",
      "10441.ppm not in CSV\n",
      "03373.ppm not in CSV\n",
      "11777.ppm not in CSV\n",
      "01564.ppm not in CSV\n",
      "10469.ppm not in CSV\n",
      "08226.ppm not in CSV\n",
      "07115.ppm not in CSV\n",
      "08540.ppm not in CSV\n",
      "07673.ppm not in CSV\n",
      "09886.ppm not in CSV\n",
      "01202.ppm not in CSV\n",
      "12518.ppm not in CSV\n",
      "05070.ppm not in CSV\n",
      "03401.ppm not in CSV\n",
      "07667.ppm not in CSV\n",
      "00108.ppm not in CSV\n",
      "09892.ppm not in CSV\n",
      "01216.ppm not in CSV\n",
      "11005.ppm not in CSV\n",
      "11763.ppm not in CSV\n",
      "01570.ppm not in CSV\n",
      "07101.ppm not in CSV\n",
      "04408.ppm not in CSV\n",
      "03367.ppm not in CSV\n",
      "02079.ppm not in CSV\n",
      "05716.ppm not in CSV\n",
      "03417.ppm not in CSV\n",
      "02709.ppm not in CSV\n",
      "05066.ppm not in CSV\n",
      "01200.ppm not in CSV\n",
      "08542.ppm not in CSV\n",
      "07671.ppm not in CSV\n",
      "08224.ppm not in CSV\n",
      "00678.ppm not in CSV\n",
      "01566.ppm not in CSV\n",
      "06209.ppm not in CSV\n",
      "05700.ppm not in CSV\n",
      "05714.ppm not in CSV\n",
      "08230.ppm not in CSV\n",
      "07103.ppm not in CSV\n",
      "01572.ppm not in CSV\n",
      "11761.ppm not in CSV\n",
      "09648.ppm not in CSV\n",
      "11007.ppm not in CSV\n",
      "01214.ppm not in CSV\n",
      "09890.ppm not in CSV\n",
      "10319.ppm not in CSV\n",
      "07665.ppm not in CSV\n",
      "06553.ppm not in CSV\n",
      "10331.ppm not in CSV\n",
      "02735.ppm not in CSV\n",
      "12526.ppm not in CSV\n",
      "02053.ppm not in CSV\n",
      "04422.ppm not in CSV\n",
      "08218.ppm not in CSV\n",
      "11991.ppm not in CSV\n",
      "11749.ppm not in CSV\n",
      "10443.ppm not in CSV\n",
      "11985.ppm not in CSV\n",
      "00650.ppm not in CSV\n",
      "06221.ppm not in CSV\n",
      "09112.ppm not in CSV\n",
      "12254.ppm not in CSV\n",
      "05728.ppm not in CSV\n",
      "02047.ppm not in CSV\n",
      "04436.ppm not in CSV\n",
      "04350.ppm not in CSV\n",
      "12532.ppm not in CSV\n",
      "06547.ppm not in CSV\n",
      "09674.ppm not in CSV\n",
      "07881.ppm not in CSV\n",
      "00136.ppm not in CSV\n",
      "07659.ppm not in CSV\n",
      "10325.ppm not in CSV\n",
      "09847.ppm not in CSV\n",
      "08581.ppm not in CSV\n",
      "02912.ppm not in CSV\n",
      "00877.ppm not in CSV\n",
      "02906.ppm not in CSV\n",
      "09853.ppm not in CSV\n",
      "08595.ppm not in CSV\n",
      "05099.ppm not in CSV\n",
      "07856.ppm not in CSV\n",
      "01599.ppm not in CSV\n",
      "10494.ppm not in CSV\n",
      "00687.ppm not in CSV\n",
      "11952.ppm not in CSV\n",
      "05927.ppm not in CSV\n",
      "12283.ppm not in CSV\n",
      "02090.ppm not in CSV\n",
      "12297.ppm not in CSV\n",
      "02084.ppm not in CSV\n",
      "10480.ppm not in CSV\n",
      "11946.ppm not in CSV\n",
      "00693.ppm not in CSV\n",
      "06584.ppm not in CSV\n",
      "07842.ppm not in CSV\n",
      "04393.ppm not in CSV\n",
      "03173.ppm not in CSV\n",
      "09338.ppm not in CSV\n",
      "11577.ppm not in CSV\n",
      "01764.ppm not in CSV\n",
      "10669.ppm not in CSV\n",
      "08026.ppm not in CSV\n",
      "07473.ppm not in CSV\n",
      "08740.ppm not in CSV\n",
      "08998.ppm not in CSV\n",
      "05264.ppm not in CSV\n",
      "03615.ppm not in CSV\n",
      "05270.ppm not in CSV\n",
      "07467.ppm not in CSV\n",
      "08754.ppm not in CSV\n",
      "00308.ppm not in CSV\n",
      "01016.ppm not in CSV\n",
      "11205.ppm not in CSV\n",
      "11563.ppm not in CSV\n",
      "01770.ppm not in CSV\n",
      "07301.ppm not in CSV\n",
      "08032.ppm not in CSV\n",
      "04608.ppm not in CSV\n",
      "02279.ppm not in CSV\n",
      "09304.ppm not in CSV\n",
      "06037.ppm not in CSV\n",
      "01758.ppm not in CSV\n",
      "00446.ppm not in CSV\n",
      "10655.ppm not in CSV\n",
      "01980.ppm not in CSV\n",
      "07329.ppm not in CSV\n",
      "04620.ppm not in CSV\n",
      "02251.ppm not in CSV\n",
      "12042.ppm not in CSV\n",
      "05258.ppm not in CSV\n",
      "02537.ppm not in CSV\n",
      "04146.ppm not in CSV\n",
      "10133.ppm not in CSV\n",
      "00320.ppm not in CSV\n",
      "09462.ppm not in CSV\n",
      "08768.ppm not in CSV\n",
      "10127.ppm not in CSV\n",
      "00334.ppm not in CSV\n",
      "11239.ppm not in CSV\n",
      "09476.ppm not in CSV\n",
      "06745.ppm not in CSV\n",
      "02523.ppm not in CSV\n",
      "04152.ppm not in CSV\n",
      "04634.ppm not in CSV\n",
      "12056.ppm not in CSV\n",
      "09310.ppm not in CSV\n",
      "06023.ppm not in CSV\n",
      "10899.ppm not in CSV\n",
      "04807.ppm not in CSV\n",
      "06976.ppm not in CSV\n",
      "08797.ppm not in CSV\n",
      "06962.ppm not in CSV\n",
      "04813.ppm not in CSV\n",
      "10866.ppm not in CSV\n",
      "02292.ppm not in CSV\n",
      "12081.ppm not in CSV\n",
      "00485.ppm not in CSV\n",
      "01943.ppm not in CSV\n",
      "06792.ppm not in CSV\n",
      "04185.ppm not in CSV\n",
      "03832.ppm not in CSV\n",
      "04191.ppm not in CSV\n",
      "06786.ppm not in CSV\n",
      "07498.ppm not in CSV\n",
      "00491.ppm not in CSV\n",
      "01957.ppm not in CSV\n",
      "10682.ppm not in CSV\n",
      "02286.ppm not in CSV\n",
      "12095.ppm not in CSV\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 102\u001b[0m\n\u001b[1;32m     96\u001b[0m             j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# fgsm_tensor = fgsm_attack(model, image_tensor, y_true, 0.1, 1)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m# fgsm_image = to_pil_image(fgsm_tensor.squeeze(0))\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# fgsm_image.save(os.path.join(fgsm_dir, os.path.basename(image_path)), format='PPM')\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# To execute the function\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m createAdversarialImages()\n",
      "Cell \u001b[0;32mIn[4], line 93\u001b[0m, in \u001b[0;36mcreateAdversarialImages\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m blurred_image \u001b[38;5;241m=\u001b[39m to_pil_image(blurred_tensor\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     92\u001b[0m blurred_image\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(blur_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_path)), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPM\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 93\u001b[0m pgd_tensor \u001b[38;5;241m=\u001b[39m pgd_attack(model, image_tensor, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.04\u001b[39m, \u001b[38;5;241m10\u001b[39m, y_true)\n\u001b[1;32m     94\u001b[0m pgd_image \u001b[38;5;241m=\u001b[39m to_pil_image(pgd_tensor\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     95\u001b[0m pgd_image\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pgd_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_path)), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mpgd_attack\u001b[0;34m(model, image, epsilon, alpha, num_steps, y_true, targeted, random_start)\u001b[0m\n\u001b[1;32m     32\u001b[0m perturbed_image\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 34\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(perturbed_image)\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(outputs, y_true)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:220\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:210\u001b[0m, in \u001b[0;36mMobileNetV3._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/models/mobilenetv3.py:111\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    113\u001b[0m         result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "from torch.nn import functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from src.model import build_model  # Ensure this is correctly defined elsewhere\n",
    "\n",
    "# Define the device to use for Tensor computations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def gaussian_blur(image, kernel_size=5, sigma=2):\n",
    "    \"\"\"\n",
    "    Applies Gaussian blurring using OpenCV.\n",
    "    \"\"\"\n",
    "    image_np = image.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    image_np = (image_np * 255).astype(np.uint8)  # Scale to 0-255 range for CV2\n",
    "    blurred_np = cv2.GaussianBlur(image_np, (kernel_size, kernel_size), sigmaX=sigma)\n",
    "    blurred_tensor = to_tensor(blurred_np).unsqueeze(0)\n",
    "    return blurred_tensor\n",
    "\n",
    "def pgd_attack(model, image, epsilon, alpha, num_steps, y_true, targeted=False, random_start=True):\n",
    "    model.eval()\n",
    "    perturbed_image = image.clone().detach()\n",
    "    if random_start:\n",
    "        perturbed_image += (2 * epsilon * torch.rand_like(image) - epsilon)\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    perturbed_image.requires_grad = True\n",
    "    for _ in range(num_steps):\n",
    "        outputs = model(perturbed_image)\n",
    "        model.zero_grad()\n",
    "        loss = F.cross_entropy(outputs, y_true)\n",
    "        if targeted:\n",
    "            loss = -loss\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            perturbed_image.data += alpha * perturbed_image.grad.sign()\n",
    "            perturbation = torch.clamp(perturbed_image - image, -epsilon, epsilon)\n",
    "            perturbed_image.data = torch.clamp(image + perturbation, 0, 1)\n",
    "        perturbed_image.grad.zero_()\n",
    "    return perturbed_image.detach()\n",
    "\n",
    "def fgsm_attack(model, x, y, epsilon, iterations=1):\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    output = model(x_adv)\n",
    "    loss = F.cross_entropy(output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        x_adv += epsilon * x_adv.grad.sign()\n",
    "        x_adv = torch.clamp(x_adv, 0, 1)\n",
    "    return x_adv.detach()\n",
    "\n",
    "def createAdversarialImages():\n",
    "    sign_names_df = pd.read_csv('./input/signnames.csv')\n",
    "    gt_df = pd.read_csv('./input/GTSRB_Final_Test_GT/GT-final_test_full.csv', delimiter=',')\n",
    "    gt_df = gt_df.set_index('Filename', drop=True)\n",
    "    model = build_model(pretrained=False, fine_tune=False, num_classes=43).to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load('./outputs/model.pth', map_location=device)['model_state_dict'])\n",
    "    transform = A.Compose([ToTensorV2()])\n",
    "    base_dir = './input/GTSRB_Final_Test_Images/GTSRB/Final_Test/baseline_pgd_attack'\n",
    "    ppm_dir = os.path.join(base_dir, \"all_ppm\")\n",
    "    blur_dir = os.path.join(base_dir, 'gaussian_blur')\n",
    "    pgd_dir = os.path.join(base_dir, 'pgd_attack')\n",
    "    fgsm_dir = os.path.join(base_dir, 'fgsm_attack')\n",
    "    os.makedirs(blur_dir, exist_ok=True)\n",
    "    os.makedirs(pgd_dir, exist_ok=True)\n",
    "    os.makedirs(fgsm_dir, exist_ok=True)\n",
    "    all_images = glob(os.path.join(ppm_dir,'*.ppm'))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while j < 500:\n",
    "        image_path = all_images[i]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image_tensor = transform(image=image)['image'].unsqueeze(0).to(device)\n",
    "        i += 1\n",
    "        try:\n",
    "            y_true = torch.tensor([gt_df.loc[os.path.basename(image_path), 'ClassId']]).to(device)\n",
    "        except:\n",
    "            print(f\"{os.path.basename(image_path)} not in CSV\")\n",
    "        else:\n",
    "            blurred_tensor = gaussian_blur(image_tensor)\n",
    "            blurred_image = to_pil_image(blurred_tensor.squeeze(0))\n",
    "            blurred_image.save(os.path.join(blur_dir, os.path.basename(image_path)), format='PPM') \n",
    "            pgd_tensor = pgd_attack(model, image_tensor, 0.1, 0.04, 10, y_true)\n",
    "            pgd_image = to_pil_image(pgd_tensor.squeeze(0))\n",
    "            pgd_image.save(os.path.join(pgd_dir, os.path.basename(image_path)), format='PPM')\n",
    "            j += 1\n",
    "        # fgsm_tensor = fgsm_attack(model, image_tensor, y_true, 0.1, 1)\n",
    "        # fgsm_image = to_pil_image(fgsm_tensor.squeeze(0))\n",
    "        # fgsm_image.save(os.path.join(fgsm_dir, os.path.basename(image_path)), format='PPM')\n",
    "\n",
    "# To execute the function\n",
    "createAdversarialImages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "def filter_csv_by_images(folder_path, input_csv, output_csv):\n",
    "    # Get a list of all image filenames in the folder\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files = [f for f in image_files if f.lower().endswith(('.ppm'))]\n",
    "\n",
    "    # Open input CSV file for reading\n",
    "    with open(input_csv, 'r') as input_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        # Open output CSV file for writing\n",
    "        with open(output_csv, 'w', newline='') as output_file:\n",
    "            writer = csv.writer(output_file)\n",
    "            # Write the header row\n",
    "            writer.writerow(next(reader))\n",
    "            # Iterate through each row in the input CSV\n",
    "            for row in reader:\n",
    "                # Check if the image filename is in the list of image files\n",
    "                if row[0] in image_files:\n",
    "                    # Write the row to the output CSV\n",
    "                    writer.writerow(row)\n",
    "\n",
    "folder_path = './input/GTSRB_Final_Test_Images/GTSRB/Final_Test/gaussian_blur'\n",
    "input_csv = './input/GTSRB_Final_Test_GT/GT-final_test_full.csv'\n",
    "output_csv = './input/GTSRB_Final_Test_GT/GT-final_test_next.csv'\n",
    "\n",
    "filter_csv_by_images(folder_path, input_csv, output_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_images_in_grid_with_titles(filenames, titles):\n",
    "    \"\"\"\n",
    "    Loads and visualizes multiple PPM images in a 2x2 grid with titles.\n",
    "    \n",
    "    Args:\n",
    "        filenames (list of str): The paths to the PPM image files.\n",
    "        titles (list of str): Titles for each image corresponding to their folders.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(4, 4))  # Set up a 2x2 grid of subplots\n",
    "    axs = axs.ravel()  # Flatten the 2x2 grid to a 1D array for easier indexing\n",
    "    \n",
    "    for i, (filename, title) in enumerate(zip(filenames, titles)):\n",
    "        image = Image.open(filename)\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].set_title(title)  # Set the title for each subplot\n",
    "        axs[i].axis('off')  # Turn off axis numbers and ticks for each subplot\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "base_path = \"/Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/input/GTSRB_Final_Test_Images/GTSRB/Final_Test\"  # Change this to the correct base path\n",
    "image_name = \"11776.ppm\"  # Your image name\n",
    "\n",
    "folders = [\"Images\", \"gaussian_blur\", \"fgsm_attack\", \"pgd_attack\"]\n",
    "titles = [\"Original Image\", \"Gaussian Blur\", \"FGSM Attack\", \"PGD Attack\"]  # Titles based on folders\n",
    "file_paths = [f\"{base_path}/{folder}/{image_name}\" for folder in folders]\n",
    "\n",
    "visualize_images_in_grid_with_titles(file_paths, titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py gaussian_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py pgd_attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py fgsm_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the paths to the directories\n",
    "base_dir = '../input/GTSRB_Final_Test_Images/GTSRB/Final_Test'\n",
    "gaussian_blur_dir = os.path.join(base_dir, 'gaussian_blur')\n",
    "images_dir = os.path.join(base_dir, 'Images')\n",
    "test_orig_dir = os.path.join(base_dir, 'original_subset')\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(test_orig_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of filenames from the gaussian_blur directory\n",
    "gaussian_files = os.listdir(gaussian_blur_dir)\n",
    "gaussian_filenames = [os.path.splitext(file)[0] for file in gaussian_files]\n",
    "\n",
    "# Copy files from the Images directory to test_orig if they exist in gaussian_blur\n",
    "for filename in gaussian_filenames:\n",
    "    src_path = os.path.join(images_dir, filename + '.ppm')\n",
    "    dst_path = os.path.join(test_orig_dir, filename + '.ppm')\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        print(f\"Copied {src_path} to {dst_path}\")\n",
    "    else:\n",
    "        print(f\"File does not exist: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/input/GTSRB_Final_Test_Images/GTSRB/Final_Test/fgsm_attack'\n",
    "# !rm *.ppm\n",
    "# %cd '/Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/input/GTSRB_Final_Test_Images/GTSRB/Final_Test/gaussian_blur'\n",
    "# !rm *.ppm\n",
    "# %cd '/Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/input/GTSRB_Final_Test_Images/GTSRB/Final_Test/pgd_attack'\n",
    "# !rm *.ppm\n",
    "# %cd '/Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/input/GTSRB_Final_Test_Images/GTSRB/Final_Test/original_subset'\n",
    "# !rm *.ppm\n",
    "# %cd /Users/gman/Desktop/Traffic_Sign_Recognition_using_PyTorch_and_Deep_Learning/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert .ppm to .jpg (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def convert_ppm_to_jpg(source_dir, target_dir):\n",
    "    \"\"\"\n",
    "    Converts all PPM images in the specified directory to JPG format and saves them in a new directory.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): The directory containing PPM images.\n",
    "        target_dir (str): The directory to save converted JPG images.\n",
    "    \"\"\"\n",
    "    # Check if the source directory exists\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Source directory '{source_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Create target directory if it does not exist\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "        print(f\"Created directory '{target_dir}'.\")\n",
    "\n",
    "    # Glob to find all ppm files in the source directory\n",
    "    ppm_files = glob.glob(os.path.join(source_dir, '*.ppm'))\n",
    "    if not ppm_files:\n",
    "        print(f\"No .ppm files found in '{source_dir}'.\")\n",
    "        return\n",
    "\n",
    "    for ppm_path in ppm_files:\n",
    "        try:\n",
    "            # Read the image using cv2\n",
    "            image = cv2.imread(ppm_path)\n",
    "            if image is None:\n",
    "                print(f\"Failed to read image from '{ppm_path}'.\")\n",
    "                continue\n",
    "\n",
    "            # No need to convert to RGB as we are saving directly to JPEG which expects BGR\n",
    "            # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Generate new file path with the .jpg extension\n",
    "            base_name = os.path.basename(ppm_path)\n",
    "            jpg_name = os.path.splitext(base_name)[0] + '.jpg'\n",
    "            jpg_path = os.path.join(target_dir, jpg_name)\n",
    "            \n",
    "            # Save the image in JPG format\n",
    "            cv2.imwrite(jpg_path, image)  # Save directly using the original BGR format\n",
    "            print(f\"Converted and saved {jpg_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing {ppm_path}: {e}\")\n",
    "\n",
    "\n",
    "source_directory = '../input/GTSRB_Final_Test_Images/GTSRB/Final_Test/Images'  # adjust path as needed\n",
    "target_directory = '../input/GTSRB_Final_Test_Images/GTSRB/Final_Test/Images_jpg'\n",
    "\n",
    "convert_ppm_to_jpg(source_directory, target_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize .ppm image ( Just one )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize_ppm(filename):\n",
    "#     \"\"\"\n",
    "#     Loads and visualizes a PPM image.\n",
    "    \n",
    "#     Args:\n",
    "#         filename (str): The path to the PPM image file.\n",
    "#     \"\"\"\n",
    "#     image = Image.open(filename)\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis('off')  # Turn off axis numbers and ticks\n",
    "#     plt.show()\n",
    "# print(\"Original\")\n",
    "# visualize_ppm('../input/GTSRB_Final_Test_Images/GTSRB/Final_Test/Images/00000.ppm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################          Gaussian Blur             ################## \n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "\n",
    "# def gaussian_blur(image, kernel_size=5, sigma=0):\n",
    "#     \"\"\"\n",
    "#     Applies Gaussian blurring using OpenCV.\n",
    "    \n",
    "#     Args:\n",
    "#         image (torch.Tensor): The input image tensor.\n",
    "#         kernel_size (int): The size of the Gaussian kernel. Default is 5.\n",
    "#         sigma (float): The standard deviation of the Gaussian kernel. Default is 0.\n",
    "        \n",
    "#     Returns:\n",
    "#         torch.Tensor: The blurred image tensor.\n",
    "#     \"\"\"\n",
    "#     # Convert tensor to numpy array\n",
    "#     image_np = image.squeeze(0).permute(1, 2, 0).numpy()\n",
    "#     image_np = (image_np * 255).astype(np.uint8)  # Scale to 0-255 range for CV2\n",
    "\n",
    "#     # Apply Gaussian Blur using OpenCV\n",
    "#     blurred_np = cv2.GaussianBlur(image_np, (kernel_size, kernel_size), sigmaX=sigma)\n",
    "\n",
    "#     # Convert back to tensor\n",
    "#     blurred_tensor = to_tensor(blurred_np).unsqueeze(0)\n",
    "#     return blurred_tensor\n",
    "\n",
    "\n",
    "\n",
    "# ##################          PGD attack             ################## \n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def pgd_attack(model, image, epsilon, alpha, num_steps, y_true, targeted=False):\n",
    "#     \"\"\"\n",
    "#     Perform a PGD attack on an input image.\n",
    "\n",
    "#     Args:\n",
    "#         model (torch.nn.Module): The neural network model.\n",
    "#         image (torch.Tensor): Input image tensor (should be normalized between 0 and 1).\n",
    "#         epsilon (float): Maximum perturbation amount.\n",
    "#         alpha (float): Step size per iteration.\n",
    "#         num_steps (int): Number of iterations to perform the attack.\n",
    "#         y_true (torch.Tensor): True labels for the image.\n",
    "#         targeted (bool): Set to True for targeted attacks, False for untargeted.\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: An adversarial example created from the input image.\n",
    "#     \"\"\"\n",
    "#     model.eval()  # Ensure the model is in eval mode for consistent behavior\n",
    "#     perturbed_image = image.clone().detach().requires_grad_(True)  # Initialize the perturbed image\n",
    "\n",
    "#     for _ in range(num_steps):\n",
    "#         outputs = model(perturbed_image)\n",
    "#         model.zero_grad()  # Zero gradients to avoid accumulation\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = F.cross_entropy(outputs, y_true)\n",
    "#         if targeted:\n",
    "#             loss = -loss  # Maximize the loss for targeted attack\n",
    "#         # Compute gradients\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Apply PGD formula to adjust the image\n",
    "#         with torch.no_grad():\n",
    "#             # Calculate the step using the sign of the gradients\n",
    "#             perturbed_image.data += alpha * perturbed_image.grad.sign()\n",
    "#             # Project back into the epsilon-ball and clip to valid image range\n",
    "#             perturbed_image.data = torch.clamp(perturbed_image.data, image - epsilon, image + epsilon)\n",
    "#             perturbed_image.data = torch.clamp(perturbed_image.data, 0, 1)\n",
    "\n",
    "#         # Detach and re-attach requires_grad to update gradients in next iteration\n",
    "#         perturbed_image = perturbed_image.detach().requires_grad_(True)\n",
    "\n",
    "#     return perturbed_image.detach()  # Return the perturbed image detached from the computation graph\n",
    "\n",
    "\n",
    "\n",
    "# ##################          fgsm_attack             ################## \n",
    "# def fgsm_attack(model, x, y, epsilon, iterations):\n",
    "#     \"\"\"\n",
    "#     Performs an untargeted adversarial attack using the FGSM method.\n",
    "\n",
    "#     Args:\n",
    "#         model (torch.nn.Module): The neural network model.\n",
    "#         x (torch.Tensor): Input image tensor (should be normalized between 0 and 1).\n",
    "#         y (torch.Tensor): True labels corresponding to x.\n",
    "#         epsilon (float): The perturbation magnitude.\n",
    "#         iterations (int): Number of iterations to apply the perturbation (usually 1 for FGSM).\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: Adversarial image tensor with the same shape as input x.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     x_adv = x.clone().detach().requires_grad_(True)  # Create a copy of x to modify\n",
    "#     y = y.clone().detach()\n",
    "\n",
    "#     for _ in range(iterations):\n",
    "#         output = model(x_adv)\n",
    "#         loss = F.cross_entropy(output, y)\n",
    "#         model.zero_grad()  # Zero out previous gradients\n",
    "#         loss.backward()  # Compute gradients with respect to input image\n",
    "\n",
    "#         # Apply FGSM attack by adjusting the image pixels in the direction of the gradients\n",
    "#         with torch.no_grad():\n",
    "#             x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "#             x_adv = torch.clamp(x_adv, 0, 1)  # Ensure the adversarial image is still valid\n",
    "\n",
    "#         # Reset requires_grad to True to compute new gradients in next iteration if necessary\n",
    "#         x_adv = x_adv.detach().requires_grad_(True)\n",
    "\n",
    "#     return x_adv\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming 'model' is loaded and set up, 'images' and 'labels' are prepared tensors\n",
    "# # model = load_pretrained_model()\n",
    "# # images, labels = load_data()\n",
    "# # epsilon = 0.01  # Perturbation magnitude\n",
    "# # num_iter = 1  # FGSM typically uses 1 iteration\n",
    "# # adversarial_images = untargeted_attack(model, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd outputs/test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of folders to create\n",
    "list_operations = [\n",
    "    \"baseline_original_images\",\n",
    "    \"baseline_gaussian_blur\",\n",
    "    \"baseline_fgsm_attack\",\n",
    "    \"baseline_pgd_attack\",\n",
    "    \"de-gaussian_blur\",\n",
    "    \"de-fgsm_attack\",\n",
    "    \"de-pgd_attack\",\n",
    "    \"de-fgsm_attack_light\",\n",
    "    \"de-pgd_attack_light\",\n",
    "    \"de-gaussian_blur_light\"\n",
    "]\n",
    "\n",
    "# Specify the directory where you want to create the folders\n",
    "base_directory = './'\n",
    "\n",
    "# Create folders\n",
    "for folder_name in list_operations:\n",
    "    folder_path = os.path.join(base_directory, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    print(f\"Created folder: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_original_images\n",
    "# baseline_gaussian_blur\n",
    "# baseline_fgsm_attack\n",
    "# baseline_pgd_attack\n",
    "# de-gaussian_blur\n",
    "# de-fgsm_attack\n",
    "# de-pgd_attack\n",
    "# de-fgsm_attack_light\n",
    "# de-pgd_attack_light\n",
    "# de-gaussian_blur_light\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/gman/Desktop/Traffic_sign_clone_small/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py de-gaussian_blur_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    gt_df = gt_df.set_index('Filename', drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
